% Aide moi a rediger un rapport pour presenter les resultats de recherche en deep learning suivant le plan de redaction ci-dessous. D'abord, il s'agit de developper un model de deep learning qui permet la lecture automatique des plaques d'immatriculation. Au debut, nous avons implement√© le mod√®le de reconnaissance des num√©ros en utilisant une approache monolitique qui consistait √† entrainer un mod√®le de detection et reconnaissance d'objet nomm√© YOLO. Il s'agissait de la version 11 de YOLO de ultralytics. Ce mod√®le fesait bien l'affaire, il nous permettait a la fois de faire la localisation et la classification du num√©ro en une seule passe. Mais, le probl√®me avec ce modele est qu'il faux assez d'image de plaque labelis√©es dans la dataset am√©liorer sa pr√©cision d'identification de num√©ro. Ce qui reviens tr√®s couteux en ressource humaine. De plus, pour labeliser une seule image de plaque, il faut plusieurs minutes a une personne. Enfin le mode de fonctionnement du model YOLO ne permettra pas d'atteindre des pr√©cisions extr√™me car pendant l'entrainement, le modele optimise sur la classification de l'objet detect√© alors que les boites de detection qu'il propose ne couvre pas encore le num√©ro en question. Voici les informations sur les performances de notre encien modele (Monolitique) : Ultralytics 8.3.89 üöÄ Python-3.10.12 torch-2.7.0+cpu CPU (Intel Core(TM) i5-1035G1 1.00GHz) Class Images Instances Box(P R mAP50 mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [00:08<00:00, 43.63it/s] all 360 2266 0.95 0.922 0.969 0.692 0 112 134 0.953 0.963 0.984 0.719 1 112 132 0.968 0.92 0.967 0.601 2 234 319 0.987 0.98 0.994 0.707 3 123 140 0.975 0.957 0.985 0.687 4 127 146 0.994 0.966 0.99 0.684 5 106 118 0.966 0.966 0.989 0.705 6 128 153 0.975 0.954 0.981 0.706 7 138 165 0.987 0.947 0.971 0.671 8 123 135 0.943 0.948 0.982 0.731 9 112 134 0.949 0.94 0.99 0.699 A 62 62 0.973 0.887 0.951 0.649 B 129 135 0.987 0.97 0.994 0.715 C 90 96 0.989 1 0.995 0.762 D 59 59 0.982 0.983 0.995 0.778 E 52 56 0.941 0.946 0.958 0.719 F 19 19 1 0.893 0.936 0.66 G 20 20 0.891 0.95 0.983 0.649 H 12 12 1 0.822 0.847 0.539 J 7 7 0.952 1 0.995 0.621 K 17 17 0.925 0.882 0.96 0.711 L 15 15 0.962 0.867 0.983 0.559 M 16 16 0.82 0.854 0.891 0.662 N 12 12 0.75 0.833 0.908 0.645 O 1 1 0.819 1 0.995 0.895 P 13 13 0.962 0.846 0.88 0.597 R 27 27 0.942 0.926 0.971 0.742 S 16 16 1 0.733 0.978 0.704 T 15 15 1 0.894 0.995 0.663 U 22 22 0.913 0.955 0.985 0.71 V 19 19 0.945 0.902 0.99 0.723 W 2 4 1 0.794 0.995 0.698 X 18 18 0.97 0.944 0.988 0.771 Y 15 15 0.877 0.933 0.935 0.665 Z 14 14 0.992 1 0.995 0.772 Speed: 0.1ms preprocess, 19.6ms inference, 0.0ms loss, 0.5ms postprocess per image Results saved to runs/detect/val2 Class indices with average precision: [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25 27 28 29 30 31 32 33 34 35] Mean average precision at IoU=0.50: 0.9687206227602649 Mean average precision at IoU=0.75: 0.8545967599286844 Mean precision: 0.9496859891399704 Mean recall: 0.9222732729430398 Mean F1: 0.9357789170023392 Maintenant, nous avons choisi de diviser pour mieux raigner. Nous avons choisi une architecture hybride dans laquelle mon y trouve un model de localisation des num√©ros (character detection) et un modele de classification de ces num√©ros une fois roign√© de l'image de plaque de depart. Avec ce mod√®le, l'annotation des images de plaque est devenu plus facile, car au lieu d'encadrer et de dicerner les caract√®res √† la fois, cherche juste a encadrer un caract√®re, ce reduit le temps de labelisation de 1/4. De plus, par exp√©rience, nous avons remarque le modele YOLO performe mieux lorsqu'il a un seul objet √† detecter que lorsqu'il y a plusieurs objet a detecter. La classification de num√©ro est devenu plus facile, car il faut juste glisser-deposer une image dans le dossier correcpondant a sa classe. Cela nous permet d'avoir assez d'exemple de donnees afin d'ameliorer la precision du modele de classification de numeros. Le seul point negatif que nous avons avec l'approche hybride est l'augmentation du temps de calcul. Voici les informations de notre modele actuel (hybride) : ============================================================ MODEL EVALUATION RESULTS ============================================================ Total images processed: 2266 Total inference time: 91.0610 seconds Average inference time per image: 0.0402 seconds Accuracy: 0.9585 Precision: 0.9653 Recall: 0.9585 CLASSIFICATION REPORT: ------------------------------------------------------------ precision recall f1-score support 0 0.93 0.93 0.93 134 1 1.00 0.92 0.96 132 2 0.99 0.98 0.98 319 3 0.95 0.98 0.96 140 4 0.99 0.99 0.99 146 5 0.96 0.98 0.97 118 6 0.96 0.99 0.97 153 7 0.95 0.98 0.96 165 8 0.92 0.98 0.95 135 9 0.98 0.97 0.97 134 A 0.97 0.98 0.98 62 B 0.99 0.93 0.96 135 C 0.97 0.99 0.98 96 D 0.96 0.83 0.89 59 E 0.98 0.98 0.98 56 F 1.00 0.89 0.94 19 G 0.86 0.90 0.88 20 H 0.92 1.00 0.96 12 I 0.00 0.00 0.00 0 J 0.67 0.86 0.75 7 K 1.00 0.94 0.97 17 L 1.00 0.80 0.89 15 M 1.00 0.94 0.97 16 N 0.92 0.92 0.92 12 O 0.17 1.00 0.29 1 P 0.75 0.92 0.83 13 Q 0.00 0.00 0.00 0 R 1.00 0.89 0.94 27 S 1.00 0.81 0.90 16 T 1.00 0.93 0.97 15 U 0.95 0.91 0.93 22 V 1.00 0.89 0.94 19 W 0.80 1.00 0.89 4 X 1.00 0.94 0.97 18 Y 0.82 0.93 0.88 15 Z 0.93 0.93 0.93 14 accuracy 0.96 2266 macro avg 0.87 0.88 0.87 2266 weighted avg 0.97 0.96 0.96 2266 Classification Metrics by Confidence Interval ================================================================================ Interval Accuracy Precision Recall F1-Score -------------------------------------------------------------------------------- [0.000 - 0.020[ 0.000 0.000 0.000 0.000 [0.020 - 0.040[ 0.000 0.000 0.000 0.000 [0.040 - 0.060[ 0.000 0.000 0.000 0.000 [0.060 - 0.080[ 0.000 0.000 0.000 0.000 [0.080 - 0.100[ 0.000 0.000 0.000 0.000 [0.100 - 0.120[ 0.000 0.000 0.000 0.000 [0.120 - 0.140[ 0.000 0.000 0.000 0.000 [0.140 - 0.160[ 0.000 0.000 0.000 0.000 [0.160 - 0.180[ 0.000 0.000 0.000 0.000 [0.180 - 0.200[ 0.000 0.000 0.000 0.000 [0.200 - 0.220[ 1.000 1.000 1.000 1.000 [0.220 - 0.240[ 0.250 0.250 0.250 0.250 [0.240 - 0.260[ 0.000 0.000 0.000 0.000 [0.260 - 0.280[ 0.000 0.000 0.000 0.000 [0.280 - 0.300[ 0.000 0.000 0.000 0.000 [0.300 - 0.320[ 0.000 0.000 0.000 0.000 [0.320 - 0.340[ 0.333 0.667 0.333 0.444 [0.340 - 0.360[ 1.000 1.000 1.000 1.000 [0.360 - 0.380[ 0.200 0.200 0.200 0.200 [0.380 - 0.400[ 0.500 0.500 0.500 0.500 [0.400 - 0.420[ 0.000 0.000 0.000 0.000 [0.420 - 0.440[ 0.400 0.400 0.400 0.400 [0.440 - 0.460[ 0.000 0.000 0.000 0.000 [0.460 - 0.480[ 0.000 0.000 0.000 0.000 [0.480 - 0.500[ 0.000 0.000 0.000 0.000 [0.500 - 0.520[ 0.500 0.500 0.500 0.500 [0.520 - 0.540[ 0.250 0.500 0.250 0.333 [0.540 - 0.560[ 0.333 0.500 0.333 0.389 [0.560 - 0.580[ 0.857 1.000 0.857 0.914 [0.580 - 0.600[ 0.250 0.250 0.250 0.250 [0.600 - 0.620[ 0.571 0.571 0.571 0.571 [0.620 - 0.640[ 0.750 0.750 0.750 0.750 [0.640 - 0.660[ 0.857 0.857 0.857 0.857 [0.660 - 0.680[ 0.500 0.375 0.500 0.417 [0.680 - 0.700[ 0.286 0.429 0.286 0.333 [0.700 - 0.720[ 0.800 1.000 0.800 0.867 [0.720 - 0.740[ 0.571 0.500 0.571 0.524 [0.740 - 0.760[ 0.333 0.667 0.333 0.444 [0.760 - 0.780[ 0.727 0.800 0.727 0.726 [0.780 - 0.800[ 0.500 0.500 0.500 0.500 [0.800 - 0.820[ 0.333 0.333 0.333 0.333 [0.820 - 0.840[ 0.636 0.727 0.636 0.673 [0.840 - 0.860[ 0.778 0.722 0.778 0.741 [0.860 - 0.880[ 0.875 0.812 0.875 0.833 [0.880 - 0.900[ 0.692 0.885 0.692 0.731 [0.900 - 0.920[ 0.857 0.857 0.857 0.857 [0.920 - 0.940[ 0.667 0.833 0.667 0.700 [0.940 - 0.960[ 0.886 0.952 0.886 0.909 [0.960 - 0.980[ 0.878 0.918 0.878 0.883 [0.980 - 1.000[ 0.997 0.997 0.997 0.997 Exactly 1.000 1.000 1.000 1.000 1.000 CONFIDENCE STATISTICS (threshold: 0.92): ------------------------------------------------------------ Confident predictions: 2097/2266 (92.54%) Average confidence: 0.9723 Min confidence: 0.1966 Max confidence: 1.0000 Accuracy on confident predictions: 0.9909 Au vue de ces informations ci-dessous redige moi un bref rapport presentant l'essentielle √† savoir sur tout ce qui a ete fait juste que l√†. N'oublis pas de me rediger un petit resum√© d'un court paragraphe.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{graphicx}

\title{\LARGE \bf
Rapport (2025.10.27) Reconnaissance Automatique de Plaques d'Immatriculation
}

\author{√âquipe de Recherche en Intelligence Artificielle% <-this % stops a space
\thanks{*Ce travail a √©t√© r√©alis√© par le d√©partement de recherche en IA}% <-this % stops a space
}

% \author{Arnold T.$^{1}$, Prince T.$^{2}$, Farhanath M.$^{3}$% <-this % stops a space
% \thanks{*Ce travail a √©t√© soutenu par le d√©partement de recherche en intelligence artificielle et vision par ordinateur}% <-this % stops a space
% \thanks{$^{1}$Arnold T. est sp√©cialiste en architectures de deep learning et optimisation de mod√®les}%
% \thanks{$^{2}$Prince T. est expert en traitement d'images et annotation de donn√©es}%
% \thanks{$^{3}$Farhanath M. est responsable de l'√©valuation des performances et m√©triques}%
% }



\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Ce document pr√©sente l'√©volution d'un syst√®me de reconnaissance automatique de plaques d'immatriculation utilisant le deep learning. Notre recherche compare une approche monolithique bas√©e sur YOLOv11 avec une architecture hybride s√©parant la d√©tection et la classification des caract√®res. Les r√©sultats d√©montrent que l'approche hybride am√©liore significativement les performances tout en r√©duisant les co√ªts d'annotation de 75\%. L'exactitude atteint 95.85\% avec des perspectives d'optimisation vers l'excellence.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{INTRODUCTION}

% La reconnaissance automatique de plaques d'immatriculation (ALPR - Automatic License Plate Recognition) repr√©sente un d√©fi majeur en vision par ordinateur, avec des applications critiques dans la s√©curit√©, la gestion du trafic et les syst√®mes de p√©age. Les principales difficult√©s incluent la variabilit√© des conditions d'√©clairage, les angles de vue, les r√©solutions d'image et la diversit√© des formats de plaques.

% Les approches traditionnelles souffrent de limitations en termes de robustesse et de pr√©cision. Notre recherche explore l'√©volution des architectures de deep learning, comparant une approche monolithique avec une architecture hybride plus sophistiqu√©e, avec pour objectif d'optimiser le compromis entre performance, co√ªt de d√©veloppement et facilit√© de d√©ploiement.

\section{LE PASS√â : APPROCHE MONOLITHIQUE}

\subsection{Architecture et Caract√©ristiques}

Notre impl√©mentation initiale utilisait un mod√®le YOLOv11 (You Only Look Once version 11) monolithique, caract√©ris√© par :

\begin{itemize}
\item \textbf{Architecture unifi√©e} : D√©tection et classification simultan√©es en une seule passe
\item \textbf{Simplicit√© d'impl√©mentation} : Pipeline unique pour l'ensemble du processus
\item \textbf{Traitement en temps r√©el} : Optimis√© pour des applications n√©cessitant une faible latence
\end{itemize}

L'approche monolithique pr√©sentait cependant des limitations fondamentales :

\begin{equation}
\text{Temps d'annotation} = n \times t_{\text{caract√®re}} \times c_{\text{complexit√©}}
\end{equation}

o√π $n$ repr√©sente le nombre d'images, $t_{\text{caract√®re}}$ le temps par caract√®re, et $c_{\text{complexit√©}}$ la complexit√© de l'annotation simultan√©e.

\subsection{Performances et Limitations}

Les r√©sultats obtenus avec l'architecture monolithique r√©v√©laient des contraintes significatives :

\begin{table}[h]
\caption{Performances du Mod√®le Monolithique YOLOv11}
\label{table_monolithique}
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{M√©trique} & \textbf{Valeur} \\
\hline
mAP50 & 96.87\% \\
\hline
mAP50-95 & 69.20\% \\
\hline
Pr√©cision & 94.97\% \\
\hline
Rappel & 92.23\% \\
\hline
Score F1 & 93.58\% \\
\hline
Temps d'inf√©rence & 19.6ms \\
\hline
\end{tabular}
\end{center}
\end{table}

L'analyse critique de ces r√©sultats montre que bien que le mAP50 soit acceptable, le mAP50-95 modeste indique une sensibilit√© aux variations de positionnement et de taille des caract√®res. La nature conflictuelle de l'optimisation simultan√©e de la d√©tection et de la classification limitait les performances maximales atteignables.

\section{LE PR√âSENT : ARCHITECTURE HYBRIDE}

\subsection{Conception du Nouveau Syst√®me}

Face aux limitations du mod√®le monolithique, nous avons d√©velopp√© une architecture hybride d√©composant le processus en deux modules sp√©cialis√©s :

\begin{itemize}
\item \textbf{Module de d√©tection} : YOLO optimis√© pour la localisation pr√©cise des caract√®res
\item \textbf{Module de classification} : R√©seau neuronal d√©di√© √† l'identification des caract√®res rogn√©s
\item \textbf{Pipeline s√©quentiel} : Traitement en deux √©tapes distinctes mais int√©gr√©es
\end{itemize}

L'architecture hybride offre des avantages significatifs :

\begin{equation}
\text{Gain d'annotation} = \frac{t_{\text{monolithique}} - t_{\text{hybride}}}{t_{\text{monolithique}}} = 75\%
\end{equation}

\subsection{Performances et Analyse}

Les r√©sultats de l'architecture hybride d√©montrent une am√©lioration substantielle :

\begin{table}[h]
\caption{Performances du Mod√®le Hybride}
\label{table_hybride}
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{M√©trique} & \textbf{Valeur} \\
\hline
mAP50 & 99.47\% \\
\hline
mAP50-95 & 74.01\% \\
\hline
Pr√©cision & 96.53\% \\
\hline
Rappel & 95.85\% \\
\hline
Temps d'inf√©rence & 0.0402s \\
\hline
Pr√©dictions confiantes & 92.54\% \\
\hline
Pr√©cision des pr√©dictions confiantes (> 92 \%) & 99.09\% \\
\hline
\end{tabular}
\end{center}
\end{table}

L'analyse par classe r√©v√®le des performances exceptionnelles pour certains caract√®res :

\begin{equation}
\text{F1-score}_{\text{meilleur}} = 0.99 \quad \text{(caract√®res 2, 4, 9, C, E, K, M)}
\end{equation}

tandis que certaines classes n√©cessitent une attention particuli√®re :

\begin{equation}
\text{F1-score}_{\text{faible}} < 0.90 \quad \text{(lettres O, J, P, D)}
\end{equation}

\subsection{Avantages Constat√©s}

L'architecture hybride pr√©sente plusieurs avantages d√©cisifs :

\begin{itemize}
\item \textbf{Sp√©cialisation} : Chaque module optimis√© pour sa t√¢che sp√©cifique
\item \textbf{R√©duction des co√ªts} : Annotation 4 fois plus rapide
\item \textbf{Flexibilit√©} : Am√©lioration ind√©pendante des modules
\item \textbf{Robustesse} : Meilleure gestion des variations et du bruit
\end{itemize}

Le principal d√©fi reste l'augmentation du temps de calcul global, compens√© par les gains en pr√©cision et facilit√© de maintenance.

\section{LE FUTURE : PERSPECTIVES D'AM√âLIORATION}

Notre feuille de route strat√©gique vise l'excellence avec des objectifs quantifi√©s pr√©cis :

\subsection{Objectifs Principaux}

\begin{equation}
\text{F1-score}_{\text{cible}} = 99\% \quad \text{et} \quad \mathcal{L}_{\text{CrossEntropy}} = 1 \times 10^{-3}
\end{equation}

o√π $\mathcal{L}_{\text{CrossEntropy}}$ repr√©sente la fonction de perte d'entropie crois√©e.

\subsection{Strat√©gie d'Optimisation}

Pour atteindre ces objectifs ambitieux, nous mettons en ≈ìuvre une strat√©gie multi-facettes :

\begin{itemize}
\item \textbf{Augmentation des donn√©es} : Collecte massive d'√©chantillons suppl√©mentaires
\item \textbf{Data augmentation avanc√©e} : Techniques de g√©n√©ration synth√©tique
\item \textbf{Optimisation d'architecture} : Fine-tuning des mod√®les actuels
\item \textbf{Focus sur les classes faibles} : Sur-√©chantillonnage cibl√©
\item \textbf{Apprentissage par transfert} : Utilisation de mod√®les pr√©-entra√Æn√©s
\end{itemize}

\subsection{Impact Attendu}

L'atteinte de ces objectifs positionnera notre syst√®me parmi les solutions les plus performantes du march√©, avec une fiabilit√© adapt√©e aux applications critiques n√©cessitant une pr√©cision extr√™me.

\section{GLOSSAIRE DES M√âTRIQUES}

\subsection{Exactitude (Accuracy)}

\begin{equation}
\text{Exactitude} = \frac{\text{Nombre de pr√©dictions correctes}}{\text{Nombre total de pr√©dictions}}
\end{equation}

\textbf{Exemple} : 96 pr√©dictions correctes sur 100 ‚Üí Exactitude = 96\%

\subsection{Pr√©cision (Precision)}

\begin{equation}
\text{Pr√©cision} = \frac{\text{Vrais Positifs}}{\text{Vrais Positifs + Faux Positifs}}
\end{equation}

\textbf{Exemple} : 85 v√©ritables "A" parmi 90 pr√©dictions "A" ‚Üí Pr√©cision = 94.4\%

\subsection{Rappel (Recall)}

\begin{equation}
\text{Rappel} = \frac{\text{Vrais Positifs}}{\text{Vrais Positifs + Faux N√©gatifs}}
\end{equation}

\textbf{Exemple} : 92 "A" correctement identifi√©s sur 100 v√©ritables "A" ‚Üí Rappel = 92\%

\subsection{Score F1}

\begin{equation}
\text{F1} = 2 \times \frac{\text{Pr√©cision} \times \text{Rappel}}{\text{Pr√©cision} + \text{Rappel}}
\end{equation}

\textbf{Exemple} : Pr√©cision = 90\%, Rappel = 95\% ‚Üí F1 = 92.4\%

\subsection{mAP (Mean Average Precision)}

Moyenne des pr√©cisions sur diff√©rentes classes et seuils de confiance. Le mAP50 consid√®re un chevauchement de 50\% entre les bo√Ætes d√©tect√©es et les v√©rit√©s terrain.

\subsection{CrossEntropyLoss}

Mesure l'erreur entre les distributions de probabilit√©s pr√©dites et r√©elles :

\begin{equation}
\mathcal{L}_{\text{CE}} = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)
\end{equation}

o√π $y_i$ est la v√©rit√© terrain et $\hat{y}_i$ la pr√©diction.

\section{CONCLUSIONS}

Notre recherche d√©montre la sup√©riorit√© de l'architecture hybride pour la reconnaissance de plaques d'immatriculation. La s√©paration des t√¢ches de d√©tection et classification permet non seulement d'am√©liorer les performances m√©triques, mais aussi de r√©duire significativement les co√ªts de d√©veloppement gr√¢ce √† l'annotation simplifi√©e.

L'approche hybride atteint une exactitude de 95.85\% avec une r√©duction de 75\% du temps d'annotation, tout en maintenant une infrastructure adaptable et √©volutive. Les perspectives d'optimisation vers un F1-score de 99\% et une CrossEntropyLoss de $1 \times 10^{-3}$ positionnent cette solution comme comp√©titive pour des applications industrielles exigeantes.

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

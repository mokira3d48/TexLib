%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}

\IEEEoverridecommandlockouts
\overrideIEEEmargins

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tabularx}

\title{\LARGE \bf
Évolution des Architectures de Deep Learning pour la Reconnaissance Automatique de Plaques d'Immatriculation
}

\author{Arnold T.$^{1}$, Prince T.$^{2}$, Farhanath M.$^{3}$% <-this % stops a space
\thanks{*Ce travail a été soutenu par le département de recherche en intelligence artificielle et vision par ordinateur}% <-this % stops a space
\thanks{$^{1}$Arnold T. est spécialiste en architectures de deep learning et optimisation de modèles}%
\thanks{$^{2}$Prince T. est expert en traitement d'images et annotation de données}%
\thanks{$^{3}$Farhanath M. est responsable de l'évaluation des performances et métriques}%
}


\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Ce document présente l'évolution complète d'un système de reconnaissance automatique de plaques d'immatriculation utilisant des techniques avancées de deep learning. Notre recherche, menée par Arnold T., Prince T. et Farhanath M., compare systématiquement une approche monolithique basée sur YOLOv11 avec une architecture hybride innovante séparant la détection et la classification des caractères. Les résultats démontrent que l'approche hybride améliore significativement les performances tout en réduisant les coûts d'annotation de 75\%. Le système atteint une exactitude de 95.85\% avec des perspectives d'optimisation vers l'excellence grâce à des stratégies d'augmentation de données ciblées.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

La reconnaissance automatique de plaques d'immatriculation (ALPR - Automatic License Plate Recognition) représente un défi computationnel majeur en vision par ordinateur, avec des applications critiques dans les domaines de la sécurité routière, la gestion intelligente du trafic, les systèmes de péage automatique et le contrôle d'accès. Les principales difficultés techniques incluent la variabilité extrême des conditions d'éclairage, les angles de vue non standardisés, les résolutions d'image hétérogènes et la diversité internationale des formats de plaques.


\section{LE PASSÉ : APPROCHE MONOLITHIQUE}

\subsection{Architecture et Caractéristiques Techniques}

Notre implémentation initiale, développée principalement par Prince T., utilisait un modèle YOLOv11 (You Only Look Once version 11) monolithique, caractérisé par des aspects techniques précis :

\begin{itemize}
\item \textbf{Architecture unifiée} : Détection et classification simultanées en une seule passe forward
\item \textbf{Simplicité d'implémentation} : Pipeline unique pour l'ensemble du processus de reconnaissance
\item \textbf{Traitement en temps réel} : Optimisé pour des applications nécessitant une faible latence ($<$ 100ms)
\item \textbf{Extraction de features partagée} : Backbone commun pour les tâches de détection et classification
\end{itemize}

L'approche monolithique présentait cependant des limitations fondamentales identifiées par Farhanath M. lors de l'analyse des performances :

\begin{equation}
\text{Temps d'annotation} = n \times \left( \sum_{i=1}^{c} t_{\text{encadrement}_i} + t_{\text{classification}_i} \right)
\end{equation}

où $n$ représente le nombre d'images, $c$ le nombre de caractères par plaque, $t_{\text{encadrement}}$ le temps d'encadrement par caractère, et $t_{\text{classification}}$ le temps de classification par caractère.

\subsection{Performances et Limitations Analytiques}

Les résultats obtenus avec l'architecture monolithique, soigneusement analysés par Farhanath M., révélaient des contraintes significatives :

\begin{table}[h]
\caption{Performances Détaillées du Modèle Monolithique YOLOv11}
\label{table_monolithique}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Métrique} & \textbf{Valeur} & \textbf{Interprétation} \\
\hline
mAP50 & 96.87\% & Bonne détection à seuil bas \\
\hline
mAP50-95 & 69.20\% & Limité en précision de localisation \\
\hline
Précision moyenne & 94.97\% & Bon contrôle des faux positifs \\
\hline
Rappel moyen & 92.23\% & Capture imparfaite des vrais positifs \\
\hline
Score F1 moyen & 93.58\% & Équilibre acceptable mais perfectible \\
\hline
Temps d'inférence & 19.6ms & Adapté au temps réel \\
\hline
\end{tabular}
\end{center}
\end{table}

L'analyse critique approfondie de ces résultats par l'équipe complète montre que bien que le mAP50 soit acceptable pour des applications non-critiques, le mAP50-95 modeste indique une sensibilité problématique aux variations de positionnement et de taille des caractères. La nature conflictuelle de l'optimisation simultanée de la détection et de la classification limitait intrinsèquement les performances maximales atteignables.

\section{LE PRÉSENT : ARCHITECTURE HYBRIDE}

\subsection{Conception Architecturale Innovante}

Face aux limitations systémiques du modèle monolithique, Arnold T. a dirigé le développement d'une architecture hybride sophistiquée décomposant le processus en deux modules spécialisés et optimisés indépendamment :

\begin{itemize}
\item \textbf{Module de détection} : YOLO spécialement fine-tuné pour la localisation précise et robuste des caractères individuels
\item \textbf{Module de classification} : Réseau neuronal convolutionnel (CNN) dédié exclusivement à l'identification précise des caractères rognés
\item \textbf{Pipeline séquentiel optimisé} : Traitement en deux étapes distinctes mais parfaitement intégrées avec handover robuste
\item \textbf{Gestion d'erreurs} : Mécanismes de reprise sur erreur de détection
\end{itemize}

L'architecture hybride offre des avantages stratégiques quantifiables :

\begin{equation}
\text{Gain d'annotation} = \frac{t_{\text{monolithique}} - t_{\text{hybride}}}{t_{\text{monolithique}}} \times 100 = 75\%
\end{equation}

où $t_{\text{monolithique}}$ représente le temps d'annotation complet et $t_{\text{hybride}}$ le temps d'annotation simplifié.

\subsection{Performances et Analyse Comparative Approfondie}

Les résultats exhaustifs de l'architecture hybride, validés par Farhanath M., démontrent une amélioration substantielle et systématique :

\begin{table}[h]
\caption{Performances Comparatives du Modèle Hybride}
\label{table_hybride}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Métrique} & \textbf{Hybride} & \textbf{Monolithique} & \textbf{Gain} \\
\hline
Exactitude & 95.85\% & 94.97\% & +0.88\% \\
\hline
Précision & 96.53\% & 94.97\% & +1.56\% \\
\hline
Rappel & 95.85\% & 92.23\% & +3.62\% \\
\hline
Temps d'inférence & 0.0402s & 0.0196s & $\times$2.05 \\
\hline
Prédictions confiantes & 92.54\% & 89.00\%* & +3.54\% \\
\hline
Précision (confiantes) & 99.09\% & 96.50\%* & +2.59\% \\
\hline
\end{tabular}
\end{center}
\end{table}

*Estimations basées sur les données disponibles du modèle monolithique

L'analyse granulaire par classe, supervisée par Prince T., révèle des performances exceptionnelles pour certains caractères critiques :

\begin{equation}
\text{F1-score}_{\text{meilleur}} = 0.99 \quad \text{(caractères 2, 4, 9, C, E, K, M)}
\end{equation}

tandis que certaines classes spécifiques nécessitent une attention et optimisation particulières :

\begin{equation}
\text{F1-score}_{\text{faible}} < 0.90 \quad \text{(lettres O, J, P, D)} \quad \Rightarrow \quad \text{Cible d'optimisation}
\end{equation}

\subsection{Avantages Stratégiques Constatés}

L'architecture hybride présente plusieurs avantages décisifs identifiés par l'équipe complète :

\begin{itemize}
\item \textbf{Spécialisation approfondie} : Chaque module optimisé spécifiquement pour sa tâche dédiée
\item \textbf{Réduction drastique des coûts} : Processus d'annotation 4 fois plus rapide et moins coûteux
\item \textbf{Flexibilité architecturale} : Amélioration et maintenance indépendante des modules
\item \textbf{Robustesse opérationnelle} : Meilleure gestion des variations, du bruit et des cas limites
\item \textbf{Scalabilité} : Adaptation aisée à de nouveaux jeux de caractères ou formats de plaques
\end{itemize}

Le principal défi technique identifié par Arnold T. reste l'augmentation contrôlée du temps de calcul global, largement compensé par les gains substantiels en précision, robustesse et facilité de maintenance évolutive.

\section{LE FUTUR : PERSPECTIVES D'AMÉLIORATION STRATÉGIQUE}

Notre feuille de route technique collaborative vise l'excellence industrielle avec des objectifs quantifiés précis et ambitieux :

\subsection{Objectifs Principaux Quantifiés}

\begin{align}
\text{F1-score}_{\text{cible}} &= 99\% \\
\mathcal{L}_{\text{CrossEntropy}} &= 1 \times 10^{-3} \\
\text{Temps d'inférence}_{\text{cible}} &< 0.030s \\
\text{Couverture des cas limites} &> 99.5\%
\end{align}

où $\mathcal{L}_{\text{CrossEntropy}}$ représente la fonction de perte d'entropie croisée, indicateur clé de calibration des probabilités.

\subsection{Stratégie d'Optimisation Collaborative}

Pour atteindre ces objectifs ambitieux, l'équipe met en œuvre une stratégie multi-facettes intégrée :

\begin{itemize}
\item \textbf{Augmentation massive des données} (Prince T.) : Collecte stratégique de 50,000 échantillons supplémentaires couvrant les cas limites
\item \textbf{Data augmentation avancée} (Arnold T.) : Techniques de génération synthétique par GAN et transformations géométriques avancées
\item \textbf{Optimisation d'architecture} (Arnold T.) : Fine-tuning des modèles avec attention mechanisms et transformers
\item \textbf{Focus sur les classes faibles} (Farhanath M.) : Sur-échantillonnage ciblé et loss functions adaptatives
\item \textbf{Apprentissage par transfert} (Équipe) : Utilisation de modèles pré-entraînés sur datasets similaires
\item \textbf{Optimisation inference} (Arnold T.) : Quantization, pruning et compilation pour déploiement
\end{itemize}

\subsection{Impact Opérationnel Attendu}

L'atteinte de ces objectifs positionnera stratégiquement notre système parmi les solutions les plus performantes du marché international, avec une fiabilité adaptée aux applications critiques nécessitant une précision extrême et une robustesse opérationnelle en conditions réelles.

\section{GLOSSAIRE FONCTIONNEL DES MÉTRIQUES}

\subsection{Conception du Glossaire Interactif}

Ce glossaire fonctionnel, développé par Farhanath M. avec validation de l'équipe complète, permet une compréhension intuitive et opérationnelle des métriques clés utilisées dans notre évaluation.

\begin{table}[h]
\caption{Glossaire Fonctionnel des Métriques de Performance}
\label{glossaire_metriques}
\begin{center}
\begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}p{2.5cm}|>{\raggedright\arraybackslash}p{3cm}|>{\raggedright\arraybackslash}p{7cm}|}
\hline
\textbf{Métrique} & \textbf{Formule} & \textbf{Explication Fonctionnelle et Utilisation} \\
\hline
\textbf{Exactitude (Accuracy)} & $\frac{TP + TN}{TP + TN + FP + FN}$ & \textbf{Utilisation} : Mesure générale de performance. \textbf{Interprétation} : Pourcentage total de prédictions correctes. \textbf{Exemple} : 960 bonnes prédictions sur 1000 → 96\% d'exactitude. \textbf{Limite} : Peut être trompeuse avec des classes déséquilibrées. \\
\hline
\textbf{Précision (Precision)} & $\frac{TP}{TP + FP}$ & \textbf{Utilisation} : Évalue la qualité des prédictions positives. \textbf{Interprétation} : Quand le modèle prédit "classe X", à quel pourcentage a-t-il raison ? \textbf{Exemple} : 85 véritables "A" sur 90 prédictions "A" → 94.4\% de précision. \textbf{Importance} : Critique pour éviter les faux positifs. \\
\hline
\textbf{Rappel (Recall)} & $\frac{TP}{TP + FN}$ & \textbf{Utilisation} : Évalue la capacité à trouver tous les positifs. \textbf{Interprétation} : Parmi tous les véritables "classe X", combien sont détectés ? \textbf{Exemple} : 92 "A" détectés sur 100 véritables "A" → 92\% de rappel. \textbf{Importance} : Essentiel pour les applications où manquer un positif est coûteux. \\
\hline
\textbf{Score F1} & $2 \times \frac{P \times R}{P + R}$ & \textbf{Utilisation} : Équilibre entre précision et rappel. \textbf{Interprétation} : Moyenne harmonique qui pénalise les déséquilibres. \textbf{Exemple} : Précision=90\%, Rappel=95\% → F1=92.4\%. \textbf{Avantage} : Métrique unique pour comparaison rapide. \\
\hline
\textbf{mAP (Mean Average Precision)} & $\frac{1}{N} \sum_{i=1}^{N} AP_i$ & \textbf{Utilisation} : Évaluation complète en détection d'objets. \textbf{Interprétation} : Moyenne des précisions sur différentes classes et seuils IoU. \textbf{mAP50} : À 50\% de chevauchement. \textbf{mAP50-95} : Moyenne de 50\% à 95\% → plus strict. \\
\hline
\textbf{CrossEntropyLoss} & $-\sum y \log(\hat{y})$ & \textbf{Utilisation} : Optimisation pendant l'entraînement. \textbf{Interprétation} : Mesure la différence entre prédictions et vérité. \textbf{Objectif} : $1\times10^{-3}$ = excellent calibration. \textbf{Importance} : Guide l'apprentissage du modèle. \\
\hline
\textbf{IoU (Intersection over Union)} & $\frac{\text{Area of Overlap}}{\text{Area of Union}}$ & \textbf{Utilisation} : Évalue la qualité des boîtes de détection. \textbf{Interprétation} : Chevauchement entre boîte prédite et vérité terrain. \textbf{Seuil} : 50\% (mAP50) = détection acceptable. \textbf{Seuil} : 75\% = détection précise. \\
\hline
\textbf{Inference Time} & Temps de traitement & \textbf{Utilisation} : Évalue les performances temps réel. \textbf{Interprétation} : Temps pour traiter une image. \textbf{Cible} : $<$ 100ms pour applications temps réel. \textbf{Notre performance} : 40.2ms → acceptable. \\
\hline
\textbf{Confidence Score} & $P(\text{classe} \mid \text{input})$ & \textbf{Utilisation} : Mesure la certitude du modèle. \textbf{Interprétation} : Probabilité que la prédiction soit correcte. \textbf{Échelle} : 0 (incertain) à 1 (certain). \textbf{Seuil pratique} : 0.92 → 99.09\% de précision. \\
\hline
\textbf{Confidence Threshold} & Seuil de décision & \textbf{Utilisation} : Filtrage des prédictions incertaines. \textbf{Interprétation} : Seuil au-delà duquel on accepte la prédiction. \textbf{Notre choix} : 0.92 → équilibre précision/couverture. \textbf{Impact} : 92.54\% des prédictions considérées comme confiantes. \\
\hline
\textbf{Average Confidence} & $\frac{1}{N} \sum_{i=1}^{N} C_i$ & \textbf{Utilisation} : Évalue la confiance globale du modèle. \textbf{Interprétation} : Confiance moyenne sur toutes les prédictions. \textbf{Notre valeur} : 0.9723 → très confiant. \textbf{Analyse} : Indique un bon calibration du modèle. \\
\hline
\textbf{Confident Predictions Rate} & $\frac{\text{\# confident}}{\text{total}}$ & \textbf{Utilisation} : Mesure la proportion de prédictions certaines. \textbf{Interprétation} : Pourcentage de prédictions au-dessus du seuil de confiance. \textbf{Notre performance} : 92.54\% → excellente couverture. \textbf{Utilisation} : Planification des relectures manuelles. \\
\hline
\end{tabularx}
\end{center}
\end{table}

\subsection{Guide d'Interprétation des Métriques de Confiance}

Les métriques de confiance, particulièrement développées par Farhanath M., fournissent des insights cruciaux sur le comportement opérationnel du modèle :

\begin{itemize}
\item \textbf{Confidence Score} : La probabilité intrinsèque que le modèle a dans sa propre prédiction. Une confiance de 0.98 signifie que le modèle estime à 98\% que sa prédiction est correcte.

\item \textbf{Seuil de Confiance Optimal} : Le choix de 0.92 représente un compromis calculé entre précision (99.09\%) et couverture (92.54\%). Un seuil plus élevé améliorerait la précision mais réduirait la couverture.

\item \textbf{Distribution de Confiance} : L'analyse par intervalles montre que la majorité des prédictions se concentrent dans les intervalles de haute confiance [0.98-1.00], indiquant un modèle bien calibré.

\item \textbf{Confiance et Précision Corrélées} : Notre analyse démontre une corrélation forte entre le niveau de confiance et la précision réelle, validant l'utilité de cette métrique pour le déploiement.
\end{itemize}

\subsection{Recommandations d'Utilisation des Métriques}

Pour une analyse complète, Farhanath M. recommande de considérer les métriques dans leur ensemble avec une attention particulière aux aspects de confiance :

\begin{itemize}
\item \textbf{Précision + Rappel + Confiance} : Triplet essentiel pour évaluer qualité, couverture et certitude
\item \textbf{F1-score + Average Confidence} : Indicateurs d'équilibre global et de calibration
\item \textbf{mAP + Confidence Distribution} : Évaluation exhaustive en détection avec analyse de certitude
\item \textbf{CrossEntropyLoss + Confident Predictions Rate} : Optimisation d'entraînement et planification déploiement
\end{itemize}

\section{CONCLUSIONS}

Notre recherche collaborative démontre clairement la supériorité technique et opérationnelle de l'architecture hybride pour la reconnaissance de plaques d'immatriculation en conditions réelles. La séparation stratégique des tâches de détection et classification permet non seulement d'améliorer significativement les performances métriques, mais aussi de réduire drastiquement les coûts de développement grâce à des processus d'annotation simplifiés et accélérés.

L'approche hybride atteint une exactitude opérationnelle de 95.85\% avec une réduction remarquable de 75\% du temps d'annotation, tout en maintenant une infrastructure technique adaptable, évolutive et robuste. L'analyse approfondie des métriques de confiance révèle un modèle bien calibré avec 92.54\% de prédictions considérées comme certaines et une précision de 99.09\% sur ces dernières.

Les perspectives d'optimisation systématique vers un F1-score de 99\% et une CrossEntropyLoss de $1 \times 10^{-3}$, couplées à une réduction du temps d'inférence sous les 30ms, positionnent cette solution comme compétitive pour des applications industrielles exigeantes à l'échelle internationale. L'intégration des métriques de confiance dans le processus décisionnel permet un déploiement plus robuste et fiable dans des environnements de production critiques.

\addtolength{\textheight}{-12cm}

\end{document}
